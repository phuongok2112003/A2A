from typing import Any, Dict, Callable, Awaitable
from langchain.agents.middleware import AgentMiddleware
from langgraph.types import StateSnapshot, Command
from langchain_core.messages import ToolMessage, AIMessage
import logging
import time
from config.settings import settings

logger = logging.getLogger(__name__)


class MiddlewareCustom(AgentMiddleware):
    """
    Custom middleware implement Ä‘áº§y Ä‘á»§ cÃ¡c method cá»§a AgentMiddleware
    
    Lifecycle:
    1. before_agent()      - Cháº¡y khi agent báº¯t Ä‘áº§u
    2. before_model()      - Cháº¡y trÆ°á»›c má»—i láº§n gá»i model
    3. wrap_model_call()   - Bao bá»c viá»‡c gá»i model
    4. after_model()       - Cháº¡y sau má»—i láº§n gá»i model
    5. wrap_tool_call()    - Bao bá»c viá»‡c gá»i tool
    6. after_agent()       - Cháº¡y khi agent káº¿t thÃºc
    """
    
    def __init__(self, enable_logging: bool = True):
        """
        Args:
            enable_logging: Báº­t/táº¯t logging chi tiáº¿t
        """
        super().__init__()
        self.enable_logging = enable_logging
        self.stats = {
            "agent_runs": 0,
            "model_calls": 0,
            "tool_calls": 0,
            "total_time": 0.0
        }
    
    @property
    def name(self) -> str:
        """TÃªn cá»§a middleware"""
        return "MiddlewareCustom"
    
    # ==================== AGENT LIFECYCLE ====================
    
    def before_agent(self, state, runtime) -> Dict[str, Any] | None:
        """
        Cháº¡y TRÆ¯á»šC KHI agent báº¯t Ä‘áº§u execution
        
        Use cases:
        - Initialize resources
        - Validate input state
        - Add system prompts
        - Setup context
        """
        self.stats["agent_runs"] += 1
        self._log(f"ðŸš€ Agent starting (run #{self.stats['agent_runs']})")

        print(f"\n\nbefore_agent --------- State: {state}\n Runtime: {runtime}")
        
        # VÃ­ dá»¥: ThÃªm timestamp vÃ o state
        self.start_time = time.time()
        
        # CÃ³ thá»ƒ modify state báº±ng cÃ¡ch return dict
        # return {"custom_field": "some_value"}
        
        return None
    
    async def abefore_agent(self, state, runtime) -> Dict[str, Any] | None:
        """Async version cá»§a before_agent"""
        # CÃ³ thá»ƒ cÃ³ logic async á»Ÿ Ä‘Ã¢y (gá»i API, database, etc.)
        return self.before_agent(state, runtime)
    
    def after_agent(self, state, runtime) -> Dict[str, Any] | None:
        """
        Cháº¡y SAU KHI agent hoÃ n thÃ nh execution
        
        Use cases:
        - Cleanup resources
        - Log final results
        - Save metrics
        - Post-processing
        """
        elapsed = time.time() - self.start_time
        self.stats["total_time"] += elapsed
        
        self._log(f"âœ… Agent completed in {elapsed:.2f}s")
        self._log(f"ðŸ“Š Stats: {self.stats}")
        print(f"\n\nafter_agent --------- State: {state}\n Runtime: {runtime}")
        return None
    
    async def aafter_agent(self, state, runtime) -> Dict[str, Any] | None:
        """Async version cá»§a after_agent"""
        return self.after_agent(state, runtime)
    
    # ==================== MODEL LIFECYCLE ====================
    
    def before_model(self, state, runtime) -> Dict[str, Any] | None:
        """
        Cháº¡y TRÆ¯á»šC KHI gá»i model
        
        Use cases:
        - Validate messages
        - Add context to messages
        - Log input
        - Modify state before model sees it
        """
        self.stats["model_calls"] += 1
        
        messages = state.get("messages", [])
        self._log(f"ðŸ“ Before model call #{self.stats['model_calls']} - {len(messages)} messages")
        
        # VÃ­ dá»¥: Log message cuá»‘i cÃ¹ng
        if messages:
            last_msg = messages[-1]
            self._log(f"   Last message: {type(last_msg).__name__}")
        
        # CÃ³ thá»ƒ modify state
        # return {"messages": modified_messages}
        print(f"\n\nbefore_model --------- State: {state}\n Runtime: {runtime}")
        return None
    
    async def abefore_model(self, state, runtime) -> Dict[str, Any] | None:
        """Async version cá»§a before_model"""
        return self.before_model(state, runtime)
    
    def after_model(self, state, runtime) -> Dict[str, Any] | None:
        """
        Cháº¡y SAU KHI model tráº£ vá» response
        
        Use cases:
        - Log model output
        - Validate response
        - Post-process response
        - Extract metadata
        """
        messages = state.get("messages", [])
        
        if messages:
            last_msg = messages[-1]
            self._log(f"ðŸ¤– After model - Response type: {type(last_msg).__name__}")
            
            # Log náº¿u lÃ  AIMessage
            if isinstance(last_msg, AIMessage):
                content_preview = str(last_msg.content)[:100]
                self._log(f"   Content preview: {content_preview}...")
        print(f"\n\nafter_model --------- State: {state}\n Runtime: {runtime}")
        return None
    
    async def aafter_model(self, state, runtime) -> Dict[str, Any] | None:
        """Async version cá»§a after_model"""
        return self.after_model(state, runtime)
    
    # ==================== MODEL CALL WRAPPER ====================
    
    def wrap_model_call(self, request, handler: Callable) -> Any:
        """
        BÃƒO Bá»ŒC viá»‡c gá»i model - CÃ³ quyá»n kiá»ƒm soÃ¡t hoÃ n toÃ n
        
        Use cases:
        - Retry on error
        - Cache responses
        - Modify request/response
        - Measure performance
        - Short-circuit execution
        
        Args:
            request: ModelRequest chá»©a state vÃ  runtime
            handler: Callback Ä‘á»ƒ thá»±c thi model call
            
        Returns:
            ModelResponse hoáº·c AIMessage
        """
        start = time.time()
        
        try:
            self._log(f"âš¡ Wrapping model call...")
            
            # VÃ­ dá»¥ 1: ÄÆ¡n giáº£n - chá»‰ gá»i handler
            # response = handler(request)
            
            # VÃ­ dá»¥ 2: Retry logic
            response = self._retry_model_call(request, handler, max_retries=3)
            
            elapsed = time.time() - start
            self._log(f"âš¡ Model call completed in {elapsed:.2f}s")
            print(f"\n\nwrap_model_call --------- Request: {request}\n Handler: {handler}")
            return response
            
        except Exception as e:
            self._log(f"âŒ Model call error: {e}")
            raise
    
    def _retry_model_call(self, request, handler, max_retries: int = 3):
        """Helper: Retry logic cho model call"""
        for attempt in range(max_retries):
            try:
                response = handler(request)
                
                # Validate response
                if self._is_valid_response(response):
                    return response
                    
                self._log(f"âš ï¸ Invalid response, retry {attempt + 1}/{max_retries}")
                
            except Exception as e:
                if attempt == max_retries - 1:
                    self._log(f"âŒ All retries failed")
                    raise
                    
                self._log(f"âš ï¸ Attempt {attempt + 1} failed: {e}, retrying...")
                time.sleep(0.5 * (attempt + 1))  # Exponential backoff
      
        return response
    
    def _is_valid_response(self, response) -> bool:
        """Validate model response"""
        # Implement validation logic
        return True
    
    async def awrap_model_call(
        self, 
        request, 
        handler: Callable[[Any], Awaitable[Any]]
    ) -> Any:
        """
        Async version cá»§a wrap_model_call
        """
        start = time.time()
        
        try:
            self._log(f"âš¡ Wrapping async model call...")
            
            # Async retry logic
            response = await self._async_retry_model_call(request, handler, max_retries=3)
            
            elapsed = time.time() - start
            self._log(f"âš¡ Async model call completed in {elapsed:.2f}s")
            
            return response
            
        except Exception as e:
            self._log(f"âŒ Async model call error: {e}")
            raise
    
    async def _async_retry_model_call(self, request, handler, max_retries: int = 3):
        """Helper: Async retry logic"""
        import asyncio
        
        for attempt in range(max_retries):
            try:
                response = await handler(request)
                
                if self._is_valid_response(response):
                    return response
                    
                self._log(f"âš ï¸ Invalid async response, retry {attempt + 1}/{max_retries}")
                
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                    
                self._log(f"âš ï¸ Async attempt {attempt + 1} failed: {e}")
                await asyncio.sleep(0.5 * (attempt + 1))
        
        return response
    
    # ==================== TOOL CALL WRAPPER ====================
    
    def wrap_tool_call(self, request, handler: Callable) -> ToolMessage | Command:
        """
        BÃƒO Bá»ŒC viá»‡c gá»i tool - Kiá»ƒm soÃ¡t tool execution
        
        Use cases:
        - Retry on tool errors
        - Validate tool inputs
        - Modify tool arguments
        - Cache tool results
        - Monitor tool usage
        
        Args:
            request: ToolCallRequest vá»›i tool_call dict, BaseTool, state, runtime
            handler: Callback Ä‘á»ƒ thá»±c thi tool
            
        Returns:
            ToolMessage hoáº·c Command
        """
        self.stats["tool_calls"] += 1
        
        tool_name = request.tool_call.get("name", "unknown")
        tool_args = request.tool_call.get("args", {})
        
        self._log(f"ðŸ”§ Tool call #{self.stats['tool_calls']}: {tool_name}")
        self._log(f"   Args: {tool_args}")
        
        try:
            # VÃ­ dá»¥ 1: ÄÆ¡n giáº£n - chá»‰ gá»i handler
            # result = handler(request)
            
            # VÃ­ dá»¥ 2: Retry vá»›i validation
            result = self._retry_tool_call(request, handler, max_retries=3)
            
            self._log(f"âœ… Tool {tool_name} completed successfully")
            print(f"\n\nwrap_tool_call --------- Request: {request}\n Handler: {handler}")
            return result
            
        except Exception as e:
            self._log(f"âŒ Tool {tool_name} error: {e}")
            raise
    
    def _retry_tool_call(self, request, handler, max_retries: int = 3):
        """Helper: Retry logic cho tool call"""
        for attempt in range(max_retries):
            try:
                result = handler(request)
                
                # Validate result
                if isinstance(result, ToolMessage):
                    if result.status != "error":
                        return result
                    
                    self._log(f"âš ï¸ Tool returned error status, retry {attempt + 1}/{max_retries}")
                else:
                    # Command or other result
                    return result
                
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                    
                self._log(f"âš ï¸ Tool attempt {attempt + 1} failed: {e}")
                time.sleep(0.3 * (attempt + 1))
        
        return result
    
    async def awrap_tool_call(
        self, 
        request, 
        handler: Callable[[Any], Awaitable[ToolMessage | Command]]
    ) -> ToolMessage | Command:
        """
        Async version cá»§a wrap_tool_call
        """
        self.stats["tool_calls"] += 1
        
        tool_name = request.tool_call.get("name", "unknown")
        
        self._log(f"ðŸ”§ Async tool call #{self.stats['tool_calls']}: {tool_name}")
        
        try:
            result = await self._async_retry_tool_call(request, handler, max_retries=3)
            
            self._log(f"âœ… Async tool {tool_name} completed")
            
            return result
            
        except Exception as e:
            self._log(f"âŒ Async tool {tool_name} error: {e}")
            raise
    
    async def _async_retry_tool_call(self, request, handler, max_retries: int = 3):
        """Helper: Async retry logic cho tool"""
        import asyncio
        
        for attempt in range(max_retries):
            try:
                result = await handler(request)
                
                if isinstance(result, ToolMessage) and result.status != "error":
                    return result
                elif not isinstance(result, ToolMessage):
                    return result
                    
                self._log(f"âš ï¸ Async tool error status, retry {attempt + 1}/{max_retries}")
                
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                    
                await asyncio.sleep(0.3 * (attempt + 1))
        
        return result
    
    # ==================== HELPER METHODS ====================
    
    def _log(self, message: str):
        """Helper Ä‘á»ƒ log vá»›i format Ä‘áº¹p"""
        if self.enable_logging:
            logger.info(f"[{self.name}] {message}")
    
    def get_stats(self) -> Dict[str, Any]:
        """Láº¥y thá»‘ng kÃª"""
        return self.stats.copy()
    
    def reset_stats(self):
        """Reset thá»‘ng kÃª"""
        self.stats = {
            "agent_runs": 0,
            "model_calls": 0,
            "tool_calls": 0,
            "total_time": 0.0
        }

